{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d32900-72b6-4eec-88c8-94ab458710e4",
   "metadata": {},
   "source": [
    "# Creating a Cleaned Dataset for Snow Spotter (Generic)\n",
    "\n",
    "#### Summary\n",
    "\n",
    "Zooniverse data exports provide a massive csv file with a huge range of data. However, for data analysis purposes, we are only interested in a a few fields. This script describes the general approach to create a cleaned netCDF or csv file in python. The final cleaned file will have columns for datetime, median value, mean value, and mean threshold value. Note that this code is not specific to any water year, and is only a template upon which changes must be made for a unique project. For specific code, the Snow Spotter Data Cleaning repository contains jupyter notebook files for water years 2016-2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a3d4c-725a-49ff-8361-37b77f555f9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Import the following packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b92cf27-02c2-4ff7-963a-e03d1ed19247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217fdae7-1c0e-4fd0-8be3-a9b2820bb859",
   "metadata": {},
   "source": [
    "#### Import the data export and create a dataframe with only the subject_data and annotations columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364db5d2-1ae7-43f7-8186-94a722db863d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"filepath\\\\filename.csv\", usecols = ['subject_data', 'annotations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77dc84-c877-4b72-82a1-b38786006b57",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The following code extracts the datetime from the subject_data column.\n",
    "\n",
    " * First, the cell is transformed into a dict so that we can call the 'metadata' key. \n",
    " \n",
    " * If you label your metadata column appropriately, this will already be in the form Y_m_d_HMS. If you labeled your column in another way, you will have to adjust this value so that it only contains the date. \n",
    " \n",
    " * We can then use strip the datetime, finishing creating a column with just datetimes which we will need for our analysis later on.\n",
    " \n",
    "**Important Note:** When uploading images to Zooniverse, the choice of medatata label will have an impact on the following code. It is best practice to label the metadata with only the image date and time, as this will limit the number of steps needed to extract a datetime from the classifications export. However, if something else is chosen, additional lines of code can extract the date from the metadata. While not preferable, as long as the date is somewhere within the metadata label, it can be extracted. For instance, if I had labeled my metadata with with both location and date, such as \"niwot3_2021_12_01_095605\", I would add this line of code as shown below.  \n",
    "\n",
    "```python\n",
    "    metadata = subject_dict_simple['metadata']\n",
    "    date = metadata[7:len(metadata)]\n",
    "```\n",
    "Choice of metadata label can also affect datetime extraction, and the strip datetime code can be adjusted to fit any datetime format. The code below assumes the metadata is in the form Year_Month_Day_HourMinuteSecond (such as 2021_12_01_095605)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce126aa7-3dad-40fe-8bcf-8142267b24fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = []\n",
    "row_count = len(df.index)\n",
    "def extract_meta_data(index):\n",
    "    subject_data = df.iloc[index,1]\n",
    "    #string to dict\n",
    "    subject_dict = json.loads(subject_data)\n",
    "    #shed outer layer of dict\n",
    "    shedded_subject_dict = dict(ele for sub in subject_dict.values() for ele in sub.items())\n",
    "    #extract the metadata, see important note in markdown above\n",
    "    metadata = shedded_subject_dict_simple['metadata']\n",
    "    #extract datetime, see important note in markdown above\n",
    "    date_time = datetime.strptime(date, '%Y_%m_%d_%H%M%S')\n",
    "    return date_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb13424-ce89-4d6c-8a96-5fdba0c017ea",
   "metadata": {},
   "source": [
    "#### The next function extracts the participant response\n",
    "\n",
    " * Once again, the cell must first be transformed into a dict so that we can call the 'value' key.\n",
    " \n",
    " * This value will be either \"Yes\", \"No\", or \"Unsure.\" We need to convert this into a numerical value so that we can average and graph responses later on. We use a simple loop to convert responses of \"Yes\" to 1.0, \"No\" to 0.0, and \"Unsure\" or \"It's dark\" to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedbeed5-5822-4c6c-b0ac-9b6c9f7c2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_value(index):\n",
    "    annotation = df.iloc[index,0]\n",
    "    #convert to string\n",
    "    str_annotation = str(annotation)\n",
    "    #get rid of brackets around dict\n",
    "    annotation_dict_str = str_annotation[1:len(str_annotation)-1]\n",
    "    #string to dict\n",
    "    annotation_dict = json.loads(annotation_dict_str)\n",
    "    #grab yes or no value from dict \n",
    "    annotation_value = annotation_dict['value']\n",
    "\n",
    "    if(annotation_value == \"Yes\"): \n",
    "        return 1\n",
    "    elif(annotation_value == \"No\"): \n",
    "        return 0\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fb7154-1ae5-4287-90e5-03d716f01b44",
   "metadata": {},
   "source": [
    "#### Combine the extracted datetime and reponse into a new dataframe, then calculate and combine the median and mean response for each datetime. \n",
    "\n",
    "The resulting dataframe will have one column for datetime, one column for median_value, and one column for mean_value. In additiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc081c99-6610-4a2d-9189-c43134eabd3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0       \n",
    "while (i < 65449):\n",
    "    i = i + 1\n",
    "    data = []\n",
    "    data.append(extract_meta_data(i))\n",
    "    data.append(extract_value(i))\n",
    "    arr.append(data)\n",
    "    \n",
    "    \n",
    "final = pd.DataFrame(arr, columns = ['datetime','value'])\n",
    "\n",
    "#average 15 participant responses\n",
    "median_final = final.groupby('datetime').median().reset_index()\n",
    "mean_final = final.groupby('datetime').mean().reset_index()\n",
    "combined_final = median_final\n",
    "combined_final['mean_value'] = mean_final.value\n",
    "combined_final.columns = ['datetime', 'median_value', 'mean_value']\n",
    "combined_final['mean_threshold'] = np.where(combined_final['mean_value'] >= 0.9, 1, np.where(np.isnan(combined_final['mean_value']), np.nan, 0))\n",
    "combined_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ab9a9d-21f0-4c6c-b0c1-bc03f24b7857",
   "metadata": {},
   "source": [
    "##### Save the cleaned data set as a netCDF file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f14401a4-b921-4056-b28c-c8630bccb2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_export = combined_final.to_xarray()\n",
    "cleaned_export.to_netcdf(\"filepath\\\\filename.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531d603-39cb-4ca3-88ea-75ebb0872242",
   "metadata": {},
   "source": [
    "##### ... or as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c5d28-3a87-4d60-923f-a00df90a66b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_final.to_csv(\"filepath\\\\filename.csv\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
