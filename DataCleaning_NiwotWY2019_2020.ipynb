{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00aa5b45-14ed-4530-964d-862332f7bce2",
   "metadata": {},
   "source": [
    "# Creating a Cleaned Dataset for Snow Spotter \n",
    "\n",
    "#### Summary\n",
    "\n",
    "When you ask for a data export, Zooniverse will provide a massive csv file with a huge range of data. However, for data analysis purposes, we are only interested in specific fields from two columns, so the first step is to have pandas read in only the annotations and subject_data columns. Within these columns is the metadata containing the image datetime that was provided in the initial manifest upload as well as the participant response for each image. We can use a series of transformations to extract this information. \n",
    "\n",
    "From here, the next step is to convert Yes/No/Unsure responses into a numerical values and then average the reponses for each individual image. This can be done by converting \"Yes\" responses to a value of 1.0, \"No\" responses to a value of 0.0, and \"Unsure\" responses to NaN. Then, the median and mean of these values is taken and combined into a single dataset, which will be saved as a netCDF file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432951be-2aa4-4276-ac54-d26472fae401",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### First we need to import the following packages, which will be used throughout following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec6b40c4-e6f6-40e6-9c19-92ec787b7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a2867-a694-4e4e-920e-c29157264cbc",
   "metadata": {},
   "source": [
    "#### Now we can import the data export as a dataframe and have pandas read the subject_data and annotations columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f24f344-8c92-439d-9d93-0c53c7631c30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"70271195\":{\"retired\":{\"id\":116040133,\"workflow_id\":24097,\"classifications_count\":15,\"created_at\":\"2023-05-08T00:09:14.330Z\",\"updated_at\":\"2023-05-13T02:49:34.219Z\",\"retired_at\":\"2023-05-13T02:49:34.209Z\",\"subject_id\":70271195,\"retirement_reason\":\"classification_count\"},\"Filename\":\"niwot3_2020_10_07_090006.jpg\"}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[{\"task\":\"T0\",\"task_label\":\"Is there snow in the tree branches?\",\"value\":\"No\"}]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:\\\\JohnsWork\\\\NiwotRidge\\\\Niwot_WY2021\\\\NiwotWY2021_Classifications_Data.csv\", usecols = ['subject_data', 'annotations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9cfbf5-a80e-4147-afbb-8f66233f84f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The following code extracts the datetime from the subject_data column.\n",
    "\n",
    " * First, the cell is transformed into a dict so that we can call the 'metadata' key. \n",
    " \n",
    " * If you label your metadata column appropriately, this will already be in the form Y_m_d_HMS. If you labeled your column in another way, you will have to adjust this value so that it only contains the date. \n",
    " \n",
    " * We can then use strip the datetime, finishing creating a column with just datetimes which we will need for our analysis later on.\n",
    " \n",
    "**Important Note:** When uploading images to Zooniverse, the choice of medatata label will have an impact on the following code. It is best practice to label the metadata with only the image date and time, as this will limit the number of steps needed to extract a datetime from the classifications export. However, if something else is chosen, additional lines of code can extract the date from the metadata. While not preferable, as long as the date is somewhere within the metadata label, it can be extracted. For instance, if I had labeled my metadata with with both location and date, such as \"sagehen_2021_12_01_095605\", I would add this line of code as shown below.  \n",
    "\n",
    "```python\n",
    "    metadata = subject_dict_simple['metadata']\n",
    "    date = metadata[8:len(metadata)]\n",
    "```\n",
    "Choice of metadata label can also affect datetime extraction, and the strip datetime code can be adjusted to fit any datetime format. The code below assumes the metadata is in the form Year_Month_Day_HourMinuteSecond (such as 2021_12_01_095605)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc547430-363f-41eb-ae1e-d25278291d75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = []\n",
    "row_count = len(df.index)\n",
    "def extract_meta_data(index):\n",
    "    subject_data = df.iloc[index,1]\n",
    "    #string to dict\n",
    "    subject_dict = json.loads(subject_data)\n",
    "    #shed outer layer of dict\n",
    "    shedded_subject_dict = dict(ele for sub in subject_dict.values() for ele in sub.items())\n",
    "    #extract the metadata, see important note in markdown above\n",
    "    metadata = shedded_subject_dict['Filename']\n",
    "    if len(metadata) == 28:\n",
    "        date = metadata[7:len(metadata)-4]\n",
    "    else:\n",
    "        date = metadata[7:len(metadata)-8]\n",
    "    #extract datetime, see important note in markdown above\n",
    "    date_time = datetime.strptime(date, '%Y_%m_%d_%H%M%S')\n",
    "    return date_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5284def6-6587-4ece-9918-5cc11622faa5",
   "metadata": {},
   "source": [
    "#### The next function extracts the participant response\n",
    "\n",
    " * Once again, the cell must first be transformed into a dict so that we can call the 'value' key.\n",
    " \n",
    " * This value will be either \"Yes\", \"No\", or \"Unsure.\" We need to convert this into a numerical value so that we can average and graph responses later on. We use a simple if then loop to convert \"Yes\" to 1.0, \"No\" to 0.0, and \"Unsure\" to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "164f4d08-62e6-49b0-8f4a-286e1259676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_value(index):\n",
    "    annotation = df.iloc[index,0]\n",
    "    #get rid of brackets \n",
    "    str_annotation = str(annotation)\n",
    "    annotation_dict_str = str_annotation[1:len(str_annotation)-1]\n",
    "    #string to dict\n",
    "    annotation_dict = json.loads(annotation_dict_str)\n",
    "    #grab yes or no value from dict \n",
    "    annotation_value = annotation_dict['value']\n",
    "\n",
    "    if(annotation_value == 'Yes'): \n",
    "        return 1\n",
    "    elif(annotation_value == 'No'): \n",
    "        return 0\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a126fa63-fb73-43e9-87ec-a5abb4d2a1f6",
   "metadata": {},
   "source": [
    "#### Now, we combine the extracted datetime and reponse into a new dataframe, and then find and combine the median and mean response for each datetime. \n",
    "\n",
    "The resulting dataframe will have one column for datetime, one column for median value, and one column for mean value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c57bc212-39cf-4077-8afa-856f750ad27f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>median_value</th>\n",
       "      <th>mean_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-01 08:00:06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-01 09:00:06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-01 10:00:05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-01 11:00:06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-01 12:00:08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  median_value  mean_value\n",
       "0 2020-10-01 08:00:06           0.0         0.0\n",
       "1 2020-10-01 09:00:06           0.0         0.0\n",
       "2 2020-10-01 10:00:05           0.0         0.0\n",
       "3 2020-10-01 11:00:06           0.0         0.0\n",
       "4 2020-10-01 12:00:08           0.0         0.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0       \n",
    "while (i < (len(df)-1)):\n",
    "    i = i + 1\n",
    "    data = []\n",
    "    data.append(extract_meta_data(i))\n",
    "    data.append(extract_value(i))\n",
    "    arr.append(data)\n",
    "    \n",
    "    \n",
    "final = pd.DataFrame(arr, columns = ['datetime','value'])\n",
    "\n",
    "median_final = final.groupby('datetime').median().reset_index()\n",
    "mean_final = final.groupby('datetime').mean().reset_index()\n",
    "combined_final = median_final\n",
    "combined_final['mean_value'] = mean_final.value\n",
    "combined_final.columns = ['datetime', 'median_value', 'mean_value']\n",
    "combined_final['mean_threshold'] = np.where(combined_final['mean_value'] >= 0.9, 1, np.where(np.isnan(combined_final['mean_value']), np.nan, 0))\n",
    "combined_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae78a73-b80c-444f-97fb-35502e147fdf",
   "metadata": {},
   "source": [
    "#### Save the cleaned data set\n",
    "\n",
    "This code will save the cleaned dataset as a NetCDF file for easy management. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9a40f4b9-29c0-4deb-ba88-760b4d25013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_export = combined_final.to_xarray()\n",
    "cleaned_export.to_netcdf(\"D:\\\\JohnsWork\\\\NiwotRidge\\\\Cleaned Data\\\\netCDF\\\\NiwotWY2021_Cleaned_Data.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cb2364de-1bfb-44b0-bf42-b69daf7993ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_final.to_csv(\"D:\\\\JohnsWork\\\\NiwotRidge\\\\Cleaned Data\\\\csv\\\\NiwotWY2021_Cleaned_Data.csv\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
